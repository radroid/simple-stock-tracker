{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/radroid/simple-stock-tracker/blob/main/notebooks/AIDI_1100_01-02_FINAL_PROJECT_GROUP_7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coding Section 1: Scan/Parse \n",
    "\n",
    "- Scan (the last two weeks or the last week, up to you) from the “newswire” website.\n",
    "- Parse scanned news.\n",
    "\n",
    "# Coding Section 2: Search/Track/Store\n",
    "- Keep track of the news by storing the parsed news - CSV file.\n",
    "- For all parsed news, search the content of the tracked news to find at least 2-3 stock symbols in a specific industry of your choice; e.g: (TSX: TSLA); (TSX: GM).\n",
    "\n",
    "## Team Notes\n",
    "Three functions are created to carry out the tasks described above. \n",
    "- Function `page_parse()` scans [PRNewsWire.com]() and returns URLs of scanned articles.\n",
    "- Function `url_parse()` parses each article and detects any tickers mentioned in the article.\n",
    "- **Function `run_scanner()` uses the above functions and returns a pandas dataframe containing:**\n",
    "    - `Articel Date`\n",
    "    - `Article Title`\n",
    "    - `Ticker`\n",
    "    - `Article URL`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "KFeR_tJAp8Zv"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from requests_html import HTMLSession\n",
    "import requests\n",
    "\n",
    "# keep track of loading progress\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import pathlib\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "1tUOBHf_wpJ-"
   },
   "outputs": [],
   "source": [
    "# Parse particular news for tickers' mentions\n",
    "# Takes in an url of an article to pass and an instance of a parsing session from page parser\n",
    "def url_parse(parse_url, parse_session):\n",
    "    parse_request = parse_session.get(parse_url)\n",
    "    content = parse_request.html.find('section.release-body')\n",
    "    try:\n",
    "        for item in content:\n",
    "            parse_ticker = item.find('a.ticket-symbol', first=True).text\n",
    "    except AttributeError:\n",
    "        parse_ticker = None\n",
    "    try:\n",
    "        return parse_ticker\n",
    "    except UnboundLocalError:\n",
    "        return None # Return non if no tickers found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Tlm77dUA3430"
   },
   "outputs": [],
   "source": [
    "# Function to parse a particular page for all the news to later parse them for tickers.\n",
    "# Takes 2 parameters: a number of pages and initial dataset of already saved news.\n",
    "def page_parse(x, page_session, data=[]):\n",
    "    page_url = f'https://www.prnewswire.com/news-releases/english-releases/?page={x}&pagesize=100'\n",
    "    page_request = page_session.get(page_url)\n",
    "    content = page_request.html.find('div.row.arabiclistingcards')\n",
    "    for item in tqdm(content, desc='Parsing page...\\t', leave=False):\n",
    "        date = item.find('h3', first=True).text.split('ET')[-2]\n",
    "        title = item.find('h3', first=True).text.split('ET')[-1]\n",
    "        article_url = 'https://www.prnewswire.com' + item.find('a.newsreleaseconsolidatelink', first=True).attrs['href']\n",
    "        ticker = url_parse(article_url, page_session)\n",
    "        try:\n",
    "            dic = {\n",
    "              'Date': pd.to_datetime(date),\n",
    "              'Title': title,\n",
    "              'Ticker': ticker,\n",
    "              'Article URL': article_url\n",
    "            }\n",
    "            data.append(dic)\n",
    "        except Exception:\n",
    "            pass\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "34RK1mHy26gU"
   },
   "outputs": [],
   "source": [
    "# Main scanner, takes a number of pages to parse -  default `50` pages.\n",
    "# `50` pages cover a week of news\n",
    "# `100` pages cover 2 weeks of data.\n",
    "def run_scanner(pages=10):\n",
    "    session = HTMLSession()\n",
    "    data = []\n",
    "\n",
    "    for x in tqdm(range(1, pages+1), desc='Loading Pages...\\t'):\n",
    "        page_parse(x, session, data)\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    df.dropna(subset=['Ticker'], inplace=True)\n",
    "    df.set_index('Date', inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "IhJbZ31KsEvr"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05b90c06a1854c03a510d405f3345b70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading Pages...\t:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing page...\t:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing page...\t:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing page...\t:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing page...\t:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing page...\t:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing page...\t:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing page...\t:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing page...\t:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing page...\t:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing page...\t:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Taken:  178.4s\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "df = run_scanner(10)\n",
    "print(f'Time Taken: {(time.time() - t0): .1f}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 450
    },
    "id": "p7Ruv8QWMArM",
    "outputId": "9ff2ba3d-a90e-410a-d9e8-258044418fe8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Article URL</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-11-09 19:48:00</th>\n",
       "      <td>Intercorp Financial Services announces virtua...</td>\n",
       "      <td>IFS</td>\n",
       "      <td>https://www.prnewswire.com/news-releases/inter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-09 19:46:00</th>\n",
       "      <td>ICC Holdings, Inc. Reports 2021 Third Quarter...</td>\n",
       "      <td>ICCH</td>\n",
       "      <td>https://www.prnewswire.com/news-releases/icc-h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-09 19:00:00</th>\n",
       "      <td>Smith+Nephew establishes its first Medical Ed...</td>\n",
       "      <td>SNN</td>\n",
       "      <td>https://www.prnewswire.com/news-releases/smith...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-09 18:56:00</th>\n",
       "      <td>Cambridge Bancorp Announces Expansion of Weal...</td>\n",
       "      <td>CATC</td>\n",
       "      <td>https://www.prnewswire.com/news-releases/cambr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-09 18:35:00</th>\n",
       "      <td>EQT Ventures and EQT Growth to exit its holdi...</td>\n",
       "      <td>DASH</td>\n",
       "      <td>https://www.prnewswire.com/news-releases/eqt-v...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                 Title Ticker  \\\n",
       "Date                                                                            \n",
       "2021-11-09 19:48:00   Intercorp Financial Services announces virtua...    IFS   \n",
       "2021-11-09 19:46:00   ICC Holdings, Inc. Reports 2021 Third Quarter...   ICCH   \n",
       "2021-11-09 19:00:00   Smith+Nephew establishes its first Medical Ed...    SNN   \n",
       "2021-11-09 18:56:00   Cambridge Bancorp Announces Expansion of Weal...   CATC   \n",
       "2021-11-09 18:35:00   EQT Ventures and EQT Growth to exit its holdi...   DASH   \n",
       "\n",
       "                                                           Article URL  \n",
       "Date                                                                    \n",
       "2021-11-09 19:48:00  https://www.prnewswire.com/news-releases/inter...  \n",
       "2021-11-09 19:46:00  https://www.prnewswire.com/news-releases/icc-h...  \n",
       "2021-11-09 19:00:00  https://www.prnewswire.com/news-releases/smith...  \n",
       "2021-11-09 18:56:00  https://www.prnewswire.com/news-releases/cambr...  \n",
       "2021-11-09 18:35:00  https://www.prnewswire.com/news-releases/eqt-v...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the file\n",
    "In this section we will save the Pandas DataFrame created above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "-hE31yO46o7S"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'09Nov21-to-09Nov21.csv'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create filename using the first and last dates.\n",
    "sorted_df = df.sort_values('Date')\n",
    "\n",
    "start_date = sorted_df.index[0].date()\n",
    "end_date = sorted_df.sort_values('Date').index[-1].date()\n",
    "\n",
    "# concate dates to create name for the CSV file.\n",
    "filename = start_date.strftime('%d%b%y') + '-to-' + end_date.strftime('%d%b%y') + '.csv'\n",
    "\n",
    "filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "-hE31yO46o7S"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file saved to: ..\\datasets\\09Nov21-to-09Nov21.csv\n"
     ]
    }
   ],
   "source": [
    "data_dir = pathlib.Path('../datasets/')\n",
    "\n",
    "if data_dir.exists():\n",
    "    df.to_csv(data_dir / filename) # Save dataframe as a csv for further analysis\n",
    "    print(f'CSV file saved to: {data_dir / filename}')\n",
    "else:\n",
    "    print('Please define a valid directory to save the CSV file to.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "scan_parse.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
