{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "colab": {
      "name": "scan_parse.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.9.7 64-bit"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.7",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "interpreter": {
      "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "source": [
        "!pip install requests_html"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Collecting requests_html\n",
            "  Downloading requests_html-0.10.0-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: requests in /usr/lib/python3.9/site-packages (from requests_html) (2.26.0)\n",
            "Collecting bs4\n",
            "  Downloading bs4-0.0.1.tar.gz (1.1 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25hCollecting w3lib\n",
            "  Downloading w3lib-1.22.0-py2.py3-none-any.whl (20 kB)\n",
            "Collecting pyquery\n",
            "  Downloading pyquery-1.4.3-py3-none-any.whl (22 kB)\n",
            "Collecting fake-useragent\n",
            "  Downloading fake-useragent-0.1.11.tar.gz (13 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25hCollecting pyppeteer>=0.0.14\n",
            "  Downloading pyppeteer-0.2.6-py3-none-any.whl (83 kB)\n",
            "     |████████████████████████████████| 83 kB 2.5 MB/s             \n",
            "\u001b[?25hCollecting parse\n",
            "  Downloading parse-1.19.0.tar.gz (30 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25hRequirement already satisfied: tqdm<5.0.0,>=4.42.1 in /home/praharshb/.local/lib/python3.9/site-packages (from pyppeteer>=0.0.14->requests_html) (4.62.3)\n",
            "Requirement already satisfied: urllib3<2.0.0,>=1.25.8 in /usr/lib/python3.9/site-packages (from pyppeteer>=0.0.14->requests_html) (1.26.7)\n",
            "Requirement already satisfied: appdirs<2.0.0,>=1.4.3 in /usr/lib/python3.9/site-packages (from pyppeteer>=0.0.14->requests_html) (1.4.4)\n",
            "Collecting websockets<10.0,>=9.1\n",
            "  Downloading websockets-9.1-cp39-cp39-manylinux2010_x86_64.whl (102 kB)\n",
            "     |████████████████████████████████| 102 kB 3.5 MB/s            \n",
            "\u001b[?25hCollecting pyee<9.0.0,>=8.1.0\n",
            "  Downloading pyee-8.2.2-py2.py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: importlib-metadata>=1.4 in /usr/lib/python3.9/site-packages (from pyppeteer>=0.0.14->requests_html) (4.8.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/lib/python3.9/site-packages (from bs4->requests_html) (4.9.3)\n",
            "Requirement already satisfied: lxml>=2.1 in /usr/lib/python3.9/site-packages (from pyquery->requests_html) (4.6.3)\n",
            "Collecting cssselect>0.7.9\n",
            "  Downloading cssselect-1.1.0-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: chardet>=3.0.2 in /usr/lib/python3.9/site-packages (from requests->requests_html) (4.0.0)\n",
            "Requirement already satisfied: idna>=2.5 in /usr/lib/python3.9/site-packages (from requests->requests_html) (3.3)\n",
            "Requirement already satisfied: six>=1.4.1 in /usr/lib/python3.9/site-packages (from w3lib->requests_html) (1.16.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/lib/python3.9/site-packages (from importlib-metadata>=1.4->pyppeteer>=0.0.14->requests_html) (3.6.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/lib/python3.9/site-packages (from beautifulsoup4->bs4->requests_html) (2.2.1)\n",
            "Building wheels for collected packages: bs4, fake-useragent, parse\n",
            "  Building wheel for bs4 (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for bs4: filename=bs4-0.0.1-py3-none-any.whl size=1271 sha256=89b6059a36d6a4cf9c6bb21f46fb83169c5004e9260c5c6eb1ac5f42f2e47b68\n",
            "  Stored in directory: /home/praharshb/.cache/pip/wheels/73/2b/cb/099980278a0c9a3e57ff1a89875ec07bfa0b6fcbebb9a8cad3\n",
            "  Building wheel for fake-useragent (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for fake-useragent: filename=fake_useragent-0.1.11-py3-none-any.whl size=13502 sha256=cecb650e612334a56f51f92f16c9fb806ccc2638ad491e415fd40d50d61cca72\n",
            "  Stored in directory: /home/praharshb/.cache/pip/wheels/ae/e7/76/7dd44644d065268ab0e1b4fa2e802fa4bb0157717b7d6c6d92\n",
            "  Building wheel for parse (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for parse: filename=parse-1.19.0-py3-none-any.whl size=24591 sha256=c867812b0aa9878b80ecb6d8679d20f3c1afefa9bde0d543de72915eb152cec8\n",
            "  Stored in directory: /home/praharshb/.cache/pip/wheels/d6/9c/58/ee3ba36897e890f3ad81e9b730791a153fce20caa4a8a474df\n",
            "Successfully built bs4 fake-useragent parse\n",
            "Installing collected packages: websockets, pyee, cssselect, w3lib, pyquery, pyppeteer, parse, fake-useragent, bs4, requests-html\n",
            "Successfully installed bs4-0.0.1 cssselect-1.1.0 fake-useragent-0.1.11 parse-1.19.0 pyee-8.2.2 pyppeteer-0.2.6 pyquery-1.4.3 requests-html-0.10.0 w3lib-1.22.0 websockets-9.1\n"
          ]
        }
      ],
      "metadata": {
        "id": "YH7OORzsqCDA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "source": [
        "from requests_html import HTMLSession\n",
        "import pandas as pd\n",
        "import requests"
      ],
      "outputs": [],
      "metadata": {
        "id": "KFeR_tJAp8Zv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "source": [
        "# Parse particular news for tickers' mentions,takes in an url of an article to pass and an instance of a parsing session from page parser\n",
        "def url_parse(parse_url, parse_session):\n",
        "  parse_request = parse_session.get(parse_url)\n",
        "  content = parse_request.html.find('section.release-body')\n",
        "\n",
        "  try:\n",
        "    for item in content:\n",
        "      parse_ticker = item.find('a.ticket-symbol', first=True).text\n",
        "  except AttributeError:\n",
        "    parse_ticker = None\n",
        "  try:\n",
        "    return parse_ticker\n",
        "  except UnboundLocalError:\n",
        "    return None # Return non if no tickers found"
      ],
      "outputs": [],
      "metadata": {
        "id": "1tUOBHf_wpJ-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "source": [
        "# Function to parse a parse a particular page for all the news to later parse them for tickers. Takes 2 parameters: a number of pages and initial dataset of already saved news.\n",
        "def page_parse(x, page_session, data=[]):\n",
        "    page_url = f'https://www.prnewswire.com/news-releases/english-releases/?page={x}&pagesize=100'\n",
        "    page_request = page_session.get(page_url)\n",
        "    content = page_request.html.find('div.row.arabiclistingcards')\n",
        "    for item in content:\n",
        "        date = item.find('h3', first=True).text.split('ET')[-2]\n",
        "        title = item.find('h3', first=True).text.split('ET')[-1]\n",
        "        article_url = 'https://www.prnewswire.com' + item.find('a.newsreleaseconsolidatelink', first=True).attrs['href']\n",
        "        ticker = url_parse(article_url, page_session)\n",
        "        try:\n",
        "          dic = {\n",
        "              'Date': pd.to_datetime(date),\n",
        "              'Title': title,\n",
        "              'Ticker': ticker\n",
        "          }\n",
        "        except Exception:\n",
        "          pass\n",
        "        data.append(dic)\n",
        "    return data"
      ],
      "outputs": [],
      "metadata": {
        "id": "Tlm77dUA3430"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "source": [
        "# Main scanner, takes a number of pages to parse with 10 being a default. 50 pages cover a week of news and 100 pages cover 2 weeks of data.\n",
        "def run_scanner(pages=10):\n",
        "  session = HTMLSession()\n",
        "  data = []\n",
        "\n",
        "  for x in range(1, pages+1):\n",
        "      page_parse(x, session, data)\n",
        "\n",
        "  df = pd.DataFrame(data)\n",
        "  df.dropna(subset=['Ticker'], inplace=True)\n",
        "  df.set_index('Date', inplace=True)\n",
        "  return df"
      ],
      "outputs": [],
      "metadata": {
        "id": "34RK1mHy26gU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "source": [
        "df = run_scanner(10)"
      ],
      "outputs": [],
      "metadata": {
        "id": "IhJbZ31KsEvr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "source": [
        "df"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Title</th>\n",
              "      <th>Ticker</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2021-11-07 13:45:00</th>\n",
              "      <td>ROSEN, A LONGSTANDING LAW FIRM, Encourages Hö...</td>\n",
              "      <td>HMLP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-11-07 12:00:00</th>\n",
              "      <td>FirstEnergy Announces Transformative $3.4 Bil...</td>\n",
              "      <td>FE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-11-07 07:05:00</th>\n",
              "      <td>Phase 2 study results of Ionis' novel antisen...</td>\n",
              "      <td>IONS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-11-07 02:35:00</th>\n",
              "      <td>Elbit Systems Schedules Third Quarter 2021 Re...</td>\n",
              "      <td>ESLT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-11-06 15:06:00</th>\n",
              "      <td>CEI DEADLINE: Camber Energy, Inc. Investors w...</td>\n",
              "      <td>CEI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-11-04 13:51:00</th>\n",
              "      <td>Shareholder Alert: Ademi LLP investigates whe...</td>\n",
              "      <td>PTRS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-11-04 13:39:00</th>\n",
              "      <td>Shareholder Alert: Ademi LLP investigates whe...</td>\n",
              "      <td>LEVL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-11-04 13:36:00</th>\n",
              "      <td>Shareholder Alert: Ademi LLP investigates whe...</td>\n",
              "      <td>NPTN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-11-04 13:33:00</th>\n",
              "      <td>Metaverse Talk Heats Up Interest in Multiple ...</td>\n",
              "      <td>HOOD</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-11-04 13:30:00</th>\n",
              "      <td>SoCalGas Opens New Renewable Natural Gas Fuel...</td>\n",
              "      <td>SRE</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>377 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                 Title Ticker\n",
              "Date                                                                         \n",
              "2021-11-07 13:45:00   ROSEN, A LONGSTANDING LAW FIRM, Encourages Hö...   HMLP\n",
              "2021-11-07 12:00:00   FirstEnergy Announces Transformative $3.4 Bil...     FE\n",
              "2021-11-07 07:05:00   Phase 2 study results of Ionis' novel antisen...   IONS\n",
              "2021-11-07 02:35:00   Elbit Systems Schedules Third Quarter 2021 Re...   ESLT\n",
              "2021-11-06 15:06:00   CEI DEADLINE: Camber Energy, Inc. Investors w...    CEI\n",
              "...                                                                ...    ...\n",
              "2021-11-04 13:51:00   Shareholder Alert: Ademi LLP investigates whe...   PTRS\n",
              "2021-11-04 13:39:00   Shareholder Alert: Ademi LLP investigates whe...   LEVL\n",
              "2021-11-04 13:36:00   Shareholder Alert: Ademi LLP investigates whe...   NPTN\n",
              "2021-11-04 13:33:00   Metaverse Talk Heats Up Interest in Multiple ...   HOOD\n",
              "2021-11-04 13:30:00   SoCalGas Opens New Renewable Natural Gas Fuel...    SRE\n",
              "\n",
              "[377 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "id": "p7Ruv8QWMArM",
        "outputId": "9ff2ba3d-a90e-410a-d9e8-258044418fe8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "source": [
        "df.to_csv('Oct25Nov6.csv') # Save dataframe as a csv for further analysis"
      ],
      "outputs": [],
      "metadata": {
        "id": "-hE31yO46o7S"
      }
    }
  ]
}